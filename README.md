# üî¨ Cervical Cancer Detection System

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A deep learning-based dual-stage pipeline for automated cervical cancer detection using medical imaging. This system combines dual head **image segmentation** and feauture attention **classification** models to analyze cervical cell images.

---

## üìã Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Models](#-models)
- [Installation](#-installation)
- [Usage](#-usage)
- [Training Pipeline](#-training-pipeline)
- [Evaluation](#-evaluation)
- [Requirements](#-requirements)
- [Contributing](#-contributing)

---

## Overview

This project implements a **two-stage deep learning pipeline** for cervical cancer detection:

1. **Stage 1: Segmentation** - Identifies and segments cytoplasm and nucleus regions in cervical cell images
2. **Stage 2: Classification** - Classifies cells into different cancer stages based on segmented features

### Key Features
**Dual-Head Attention U-Net** for precise cell segmentation  
**ConvNeXt-based Classifier** with attention mechanisms  
**Multi-class Classification** (5 cancer stages)  
**Channel Attention (CBAM)** for improved feature extraction  
**Attention Gates** for better skip connections  

---

## Architecture

### Pipeline Overview

```
Input Image (Cervical Cell)
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  SEGMENTATION      ‚îÇ
    ‚îÇ  (Stage 1)         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Segmented Masks:
    - Cytoplasm Mask
    - Nucleus Mask
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  CLASSIFICATION    ‚îÇ
    ‚îÇ  (Stage 2)         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Cancer Stage Prediction
    (Class 0-4)
```

---

## üìÅ Project Structure

```
Cervical-Cancer/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ model/                      # Model architecture definitions
‚îÇ   ‚îú‚îÄ‚îÄ segmentation_model.py     # Dual-Head Attention U-Net
‚îÇ   ‚îî‚îÄ‚îÄ classification_model.py   # ConvNeXt Attention Classifier
‚îÇ
‚îú‚îÄ‚îÄ üìÇ tools/                      # Utility functions and tools
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py            # Data loading and augmentation
‚îÇ   ‚îî‚îÄ‚îÄ metrics.py                # Evaluation metrics (IoU, Dice, etc.)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ utils/                      # Helper functions
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py          # Visualization utilities
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py          # Image preprocessing
‚îÇ
‚îú‚îÄ‚îÄ üìÇ __pycache__/               # Python cache files
‚îÇ
‚îú‚îÄ‚îÄ üìÑ main_segment.py            # Segmentation training entry point
‚îú‚îÄ‚îÄ üìÑ train_segment.py           # Segmentation training logic
‚îú‚îÄ‚îÄ üìÑ main_classify.py           # Classification training entry point
‚îú‚îÄ‚îÄ üìÑ train_classify.py          # Classification training logic
‚îú‚îÄ‚îÄ üìÑ evaluate.py                # Model evaluation script
‚îú‚îÄ‚îÄ üìÑ .gitattributes             # Git attributes
‚îî‚îÄ‚îÄ üìÑ README.md                  # Project documentation
```

---

## ü§ñ Models

### 1. Segmentation Model: Dual-Head Attention U-Net

**Architecture:** `DualHeadAttConvNeXtUNet`

#### Key Components:

- **Encoder**: ConvNeXt-Tiny (pretrained on ImageNet)
  - Extracts hierarchical features at multiple scales
  - Feature maps: [96, 192, 384, 768] channels

- **Decoder**: Attention U-Net with CBAM
  - **Attention Gates**: Focus on relevant regions during upsampling
  - **CBAM Modules**: Channel + Spatial attention for refined features
  - Symmetric decoder path: [256, 128, 64] channels

- **Dual Heads**: Separate outputs for:
  - **Cytoplasm Segmentation** (cyt)
  - **Nucleus Segmentation** (nuc)

#### Architecture Details:

```python
Input: [B, 3, 1024, 1024]
         ‚Üì
    ConvNeXt Encoder
         ‚Üì
    Features: [96, 192, 384, 768] @ [64, 32, 16, 8]
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Cyt Decoder   ‚îÇ   Nuc Decoder   ‚îÇ
    ‚îÇ   + Attention   ‚îÇ   + Attention   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì                    ‚Üì
    Cyt Mask              Nuc Mask
    [B, 1, 1024, 1024]   [B, 1, 1024, 1024]
```

#### Modules:

**CBAM (Convolutional Block Attention Module)**
- Channel Attention: Uses both avg and max pooling
- Spatial Attention: Focuses on important spatial locations
- Reduction ratio: 16

**Attention Gate**
- Gates skip connections from encoder
- Suppresses irrelevant features
- Enhances relevant spatial regions

---

### 2. Classification Model: ConvNeXt Attention Classifier

**Architecture:** `ConvNeXtAttentionClassifier`

#### Key Components:

- **Backbone**: ConvNeXt-Tiny (modified input)
  - Custom first layer for **5-channel input**:
    - 3 RGB channels (original image)
    - 2 segmentation masks (cytoplasm + nucleus)
  - Output: 768-dimensional features

- **SE Block**: Squeeze-and-Excitation
  - Channel-wise attention
  - Reduction ratio: 16

- **Attention MLP**: Multi-layer classifier
  - Self-attention on features (4 heads)
  - Layer normalization
  - Dropout regularization (0.4, 0.3)

#### Architecture Details:

```python
Input: [B, 5, 256, 256]
  (3 RGB + 2 Masks)
         ‚Üì
    ConvNeXt Features
    [B, 768, H, W]
         ‚Üì
    SE Block (Channel Attention)
         ‚Üì
    Global Average Pooling
    [B, 768]
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Attention MLP     ‚îÇ
    ‚îÇ   768 ‚Üí 512 ‚Üí 256   ‚îÇ
    ‚îÇ   + Self-Attention  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Class Predictions
    [B, num_classes]
```

#### Classification Layers:

1. **FC Layer 1**: 768 ‚Üí 512 (BatchNorm + ReLU + Dropout 0.4)
2. **Self-Attention**: 4-head multi-head attention
3. **FC Layer 2**: 512 ‚Üí 256 (BatchNorm + ReLU + Dropout 0.3)
4. **Output Layer**: 256 ‚Üí num_classes

**Number of Classes**: 5 (cervical cancer stages)

---

1. **Install dependencies**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install timm
pip install opencv-python
pip install albumentations
pip install scikit-learn
pip install matplotlib
pip install tqdm
pip install tensorboard
```

---

## üíª Usage

### Quick Start

#### 1Ô∏è‚É£ **Stage 1: Train Segmentation Model**

```bash
python main_segment.py
```

**What it does:**
- Trains the Dual-Head Attention U-Net
- Segments cytoplasm and nucleus regions
- Saves trained model weights
- Generates segmentation masks for dataset

**Output:**
- Model checkpoint: `checkpoints/segmentation_best.pth`
- Segmentation masks: `outputs/masks/`

---

#### 2Ô∏è‚É£ **Stage 2: Train Classification Model**

```bash
python main_classify.py
```

**What it does:**
- Loads pre-trained segmentation model
- Generates masks for training images
- Trains ConvNeXt classifier on RGB + masks (5 channels)
- Classifies cells into cancer stages

**Output:**
- Model checkpoint: `checkpoints/classification_best.pth`
- Training logs: `logs/classification/`

---

#### 3Ô∏è‚É£ **Evaluate Models**

```bash
python evaluate.py
```

**What it does:**
- Evaluates segmentation performance (IoU, Dice score)
- Evaluates classification performance (Accuracy, F1-score)
- Generates confusion matrices
- Saves evaluation metrics

---

## üéì Training Pipeline

### Complete Training Workflow

```mermaid
graph TD
    A[Raw Cervical Cell Images] --> B[Preprocess & Augment]
    B --> C[Train Segmentation Model]
    C --> D[Generate Segmentation Masks]
    D --> E[Create 5-Channel Input]
    E --> F[Train Classification Model]
    F --> G[Evaluate Both Models]
    G --> H[Final Predictions]
```

### Detailed Steps:

1. **Data Preparation**
   - Organize images in appropriate directories
   - Apply preprocessing (resize, normalize)
   - Create train/validation/test splits

2. **Segmentation Training**
   ```bash
   python main_segment.py --epochs 100 --batch-size 8 --lr 1e-4
   ```
   - Input: RGB images (1024√ó1024)
   - Output: Cytoplasm + Nucleus masks
   - Loss: Dice Loss + BCE Loss
   - Optimizer: AdamW

3. **Mask Generation**
   - Use trained segmentation model
   - Generate masks for entire dataset
   - Save masks for classification stage

4. **Classification Training**
   ```bash
   python main_classify.py --epochs 50 --batch-size 16 --lr 1e-4
   ```
   - Input: 5-channel images (RGB + 2 masks, 256√ó256)
   - Output: Class probabilities (5 classes)
   - Loss: Cross-Entropy Loss
   - Optimizer: AdamW with scheduler

---

## üìä Evaluation

### Segmentation Metrics

- **IoU (Intersection over Union)**: Overlap between predicted and ground truth masks
- **Dice Coefficient**: 2√óoverlap / (area1 + area2)
- **Pixel Accuracy**: Correctly classified pixels

### Classification Metrics

- **Accuracy**: Overall classification accuracy
- **Precision, Recall, F1-Score**: Per-class metrics
- **Confusion Matrix**: Class-wise predictions
- **ROC-AUC**: Area under ROC curve

## üéØ Model Performance

### Expected Performance Metrics

| Model | Metric | Score |
|-------|--------|-------|
| Segmentation | Dice (Cytoplasm) | ~0.9511 |
| Segmentation | Dice (Nucleus) | ~0.9329 |
| Classification | Accuracy | ~99.26% |
| Classification | F1-Score (macro) | ~0.9926 |

*Note: Actual performance depends on dataset quality and training configuration*

---
Made with ‚ù§Ô∏è from NiceGuy
